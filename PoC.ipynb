{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdc0641-1b65-4a14-b50d-18312510604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import streamlit as st \n",
    "from dotenv import load_dotenv\n",
    "from processText import extractPdfText, textChunks, vectorDB\n",
    "from chatWithPDF import get_conversation_chain\n",
    "from templates import css, bot_template, user_template\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import chromadb\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f869c6e-5ddd-4d58-be33-48a671523aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = ''\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab22837-2a4e-4f4b-8162-f3943c5765c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPdfText(documents):\n",
    "    \"\"\"\n",
    "    Extracts raw text from the pdfs\n",
    "    \"\"\"\n",
    "    text=\"\"\n",
    "    for pdf in documents:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text = text + page.extract_text()\n",
    "            \n",
    "    return text\n",
    "\n",
    "\n",
    "def textChunks(text, save):\n",
    "    \"\"\"\n",
    "    Splits the extracted text to chunks\n",
    "    \"\"\"\n",
    "    if not save:\n",
    "        text_splitter = CharacterTextSplitter(\n",
    "            separator=\"\\n\",\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "            )\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        \n",
    "    else:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "        )\n",
    "        chunks = text_splitter.create_documents([text])\n",
    "        \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def vectorDB(chunks):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    #embeddings = openaiEmbeddings(OPEN_API_KEY=OPEN_API_KEY)\n",
    "    vector_store = FAISS.from_texts(texts=chunks,\n",
    "                                    embedding=embeddings)\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def chromaDB(chunks, name):\n",
    "    # Clear out the database first.\n",
    "    #if os.path.exists(CHROMA_PATH):\n",
    "    #    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    # Create a new DB from the documents.\n",
    "    try:\n",
    "        db = Chroma.from_documents(\n",
    "        documents=documents, \n",
    "        embedding= OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
    "        persist_directory='db'\n",
    "        )\n",
    "        db.persist()\n",
    "    return 'your' +  name + 'dabase has been created'\n",
    "    except:\n",
    "        return 'failed'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "def get_conversation_chain(db):\n",
    "    llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm( \n",
    "    llm=llm,\n",
    "    retriever = db.as_retriever(),\n",
    "    memory = memory\n",
    "    )\n",
    "\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c857686-7c0f-48ad-bb67-a785e230be4c",
   "metadata": {},
   "source": [
    "<h2> 1 time - FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92947aee-47c4-4d73-984a-7154e2cb8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"data/Data_Scienstist.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8138a623-12f4-41aa-960a-c43914741a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = reader.pages[0]\n",
    "text = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7965f574-f55b-4cec-aaaa-c4c9026e0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = textChunks(text, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69815083-40a9-46eb-9be3-54ee2eb5a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsDB = vectorDB(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e256ac1f-6a0a-45f0-98a4-b0e4e85b70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_conversation_chain(embeddingsDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fed0fd-96f5-44b4-bd34-9e50d39073dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\genAI\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is Spyros job',\n",
       " 'chat_history': [HumanMessage(content='What is Spyros job'),\n",
       "  AIMessage(content='Spyros is a Senior Data Scientist at Pfizer.')],\n",
       " 'answer': 'Spyros is a Senior Data Scientist at Pfizer.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model({'question': 'What is Spyros job'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0c895-e1da-4af6-aecb-640dc7e2f2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34bfc6c2-f762-4b1f-8162-a0cc3aa2a342",
   "metadata": {},
   "source": [
    "<h2> save load - ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "986bd706-cee8-48d9-89c9-01243fdd34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c67746d8-34c9-4098-a64e-0ab2e7d240a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = textChunks(text, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58a5ac09-05de-4cc5-948b-74cf770c6038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"2023\\nTitle: Global Clinical Supplies\\n \\nAI alerts\\n\\uf002\\nData Science Highlights\\nData Science Highlights\\nQuantum Computing /\\n \\nQuantum Machine Learning\\n\\uf085\\nRelated interests\\nRelated interests\\nPfizer\\nSenior Data Scientist\\n | \\nApr 2022\\n - \\nPresent\\nEnd to end data science applications in Pfizers Global Clinical Supplies group.\\n- Develop a NLP based application focusing on automating the reading,\\n \\nclassiﬁcation, and severity measurement of global events and emails received by\\n \\nPﬁzer's Global Security Centers. The application aimed to identify potential risks\\n \\nfor the company's clinical centers.\\n- Created and maintained dashboards and web applications to sustain predictive\\n \\nmodels pertaining to global clinical sites. Speciﬁcally, focused on packing and\\n \\nlabeling processes and inventory lot monitoring.\\n- Supervised college interns within Pﬁzer's organization who were in the process\\n \\nof completing their dissertations. Provided guidance and mentorship to support\"\n"
     ]
    }
   ],
   "source": [
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc011a-4f32-40bf-a9b1-c78cd4f5a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0625fd0b-155c-4644-93f2-1e937bbc1b3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chromadb = Chroma.from_documents(documents=documents, \n",
    "                                 embedding= OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
    "                                 persist_directory='bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "086e5d09-2f52-4a41-86f7-9b3eca919db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromadb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e6b5a-3ef8-421b-9a73-2e8d80ea4f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9bcb2-325d-4700-af91-0e01134744c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0e089-f322-4603-911e-0e52c53024e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cec5e23c-cf63-484e-84d0-2c9138de8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory='bla', \n",
    "                  embedding_function=OpenAIEmbeddings(openai_api_key=openai_api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33e8316a-6fa4-4e56-9605-3efd72d487c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=cFCGUjc33aU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b8832b8-24ce-466b-9d3c-c9f161fd7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da4fb77a-eae9-4d96-b89f-89e4ffe0183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Spyros job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf9707-7a74-43f9-acc1-d43c9303b950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3478778f-70aa-4774-a0bd-e0a564a2189e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000131998B9750>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc2b6fc4-9419-4edc-92be-0f36497d6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_chain(db):\n",
    "    llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm( \n",
    "    llm=llm,\n",
    "    retriever = db,\n",
    "    memory = memory\n",
    "    )\n",
    "\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5201ce63-7d30-4844-b38f-e360a0d49c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferMemory(return_messages=True, memory_key='chat_history'), combine_docs_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=ChatPromptTemplate(input_variables=['context', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000131992A8C10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000013199984750>, openai_api_key=SecretStr('**********'), openai_proxy='')), document_variable_name='context'), question_generator=LLMChain(prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x00000131992A8C10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000013199984750>, openai_api_key=SecretStr('**********'), openai_proxy='')), retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000131998B9750>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_conversation_chain(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223d4ed-e71d-420d-936d-f264b14e170e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac696b-75d0-46b5-be96-e2236bf4c92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee8acf-0e1a-4355-8648-49bf855e523c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3fc7e-f129-478a-bff5-9dfeefd42ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd112c4-0b5a-4d25-8d66-291375ed29e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ee246-d1bc-4699-9f54-1b946d80a5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399aeea-9e2f-43c2-9115-f12b3e8b5c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f57732-16d2-4ef5-9fc0-8415382e8325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a000e1c-b8ed-4a94-a977-136bed82e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ef5a987-df5f-41ec-87f2-c66788136c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=openai_api_key), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1147b476-ffc6-42ac-a24f-248c8691f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = qa_chain(\"What is Spyros job?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "991656c8-9247-4d3d-8a49-67be733722f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Spyros job?',\n",
       " 'result': ' Spyros is a Data Scientist.',\n",
       " 'source_documents': [Document(page_content='Spyros\\nGeorgopoulos\\nData Scientist\\nContact\\n14, rue Chingiz T. Aitmatov\\nL-1161 Luxembourg ville\\n\\uf015\\n+30 6947508036\\n\\uf10b\\nspyros.p.georgopoulos@gmail.com\\n\\uf0e0\\nSocial\\nhttps://www.linkedin.com/in/georgop\\noulos-spyridon\\n\\uf0e1\\nhttps://github.com/ownedbyphysics?\\ntab=repositories\\n\\uf09b\\nPandas, NumPy, Matplotlib,\\n \\nSeaborn, Plotly, Scikit-learn,\\n \\nNLTK, SpaCy, Keras,\\n \\nTensorFlow, PyTorch,\\n \\nTransformers, Langchain,\\n \\nOpenAI, SciPy, Scrapy,\\n  \\nBeautifulSoup, OpenCV\\n\\uf00c\\nHTML - CSS - XPath\\n\\uf00c\\nFlask, Dash, Spotﬁre,\\n \\nTableau, Git, Unit Testing,\\n \\nTerraform scripts\\n\\uf00c\\nAWS, DSS (Dataiku)\\n\\uf00c\\nSkills\\nSkills\\nMain author in a peer-\\nreviewed publication\\n \\n(Inderscience\\n \\nsumbissions)\\nTitle: Reservoir Computing vs.\\n \\nNeural Networks in Financial\\n \\nForecasting\\n\\uf002\\nPoster presentation in the\\n \\nAnalytics Summit\\n \\nConference - New York\\n \\n2023\\nTitle: Global Clinical Supplies\\n \\nAI alerts\\n\\uf002\\nData Science Highlights\\nData Science Highlights\\nQuantum Computing /\\n \\nQuantum Machine Learning\\n\\uf085\\nRelated interests\\nRelated interests\\nPfizer'),\n",
       "  Document(page_content='University of Crete\\n - \\n2017\\nResearch: Theoretical modelling of Ultra-short laser pulses interacting with matter\\nBSc in Physics\\nAristotle University of Thessaloniki\\n - \\n2014\\nSpecialized in computational physics and non-linear dynamics\\nEducation\\nEducation'),\n",
       "  Document(page_content='p'),\n",
       "  Document(page_content='p')]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8b632-5240-49ca-95e9-f536e929c68b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
